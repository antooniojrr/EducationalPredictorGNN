import os
import torch
from torch_geometric.data import Data
from torch_geometric.utils import to_networkx
import pandas as pd
import networkx as nx

import matplotlib.pyplot as plt
import seaborn as sns

GRAPH_DIR = './data/processed/graphs/'
METRICS_MEDIA_DIR = './media/graphMetrics/'
os.makedirs(METRICS_MEDIA_DIR, exist_ok=True)

class GraphTester:        

    def load_graph(self):
        """Carga el grafo desde el archivo especificado."""
        if not os.path.exists(self.graph_path):
            raise FileNotFoundError(f"El archivo {self.graph_path} no existe.")
        
        g = torch.load(self.graph_path, weights_only=False)
        #print(f"Grafo cargado con {g.num_nodes} nodos y {g.num_edges} aristas.")
        return g

    def test_graph(self, graph_path: str = None):
        """Realiza pruebas b√°sicas en el grafo cargado y devuelve las m√©tricas obtenidas."""
        while graph_path is None:
            graph_path = self._select_graph()
            
        self.graph_path = graph_path
        self.graph: Data = self.load_graph()
        
        
        metrics = {}
        print("------------------TESTEANDO GRAFO------------------")
        # NODOS AISLADOS
        connected_nodes = torch.unique(self.graph.edge_index)
        num_connected = connected_nodes.size(0)

        num_isolated = self.graph.num_nodes - num_connected
        metrics['num_isolated_nodes'] = num_isolated

        if num_isolated > 0:
            print(f"TEST DE AISLAMIENTO: Advertencia, Hay {num_isolated} ({num_isolated/self.graph.num_nodes*100:.2f}%) nodos aislados en el grafo.")
        else:
            print("TEST DE AISLAMIENTO: No hay nodos aislados en el grafo.")

        # Comprobar la varianza de las tags de los nodos adyacentes
        var, std = self.calculate_neighbor_variance()
        metrics['neighbor_variance'] = var
        metrics['neighbor_std_dev'] = std

        print("TEST DE ADYACENCIA: Varianza de etiquetas entre vecinos calculada.")
        print(f"\t‚úÖ Varianza Media de Vecinos: {(var*100.0):.4f}")
        print(f"\tüìâ Desviaci√≥n T√≠pica Promedio: {(std*10.0):.4f} puntos")

        if std < 0.15:
            print("\tüöÄ CONCLUSI√ìN: El grafo tiene ALTA coherencia (Homofilia fuerte).")
        elif std < 0.25:
            print("\t‚ö†Ô∏è CONCLUSI√ìN: El grafo tiene coherencia MEDIA.")
        else:
            print("\t‚ùå CONCLUSI√ìN: El grafo es RUIDOSO (Vecinos con notas muy dispares).")
        
        # Comprobar outliers
        outliers = self.get_graph_outliers(threshold=0.3)
        metrics['num_outliers'] = len(outliers)
        print(f"TEST DE OUTLIERS: Se han detectado {len(outliers)} ({len(outliers)/self.graph.num_nodes*100:.2f}%) alumnos con notas considerablemente distintas a sus vecinos (>3 puntos).")

        # Comprobar conexiones en cada snapshot (si es din√°mico)
        if hasattr(self.graph, 'dynamic_edge_indices'):
            print("TEST DE DINAMICIDAD: Comprobando conexiones en cada snapshot...")
            acc_var = 0.0
            acc_std = 0.0
            max_var = -float('inf')
            min_var = float('inf')
            for t, edge_index_t in enumerate(self.graph.dynamic_edge_indices):
                print(f"\tSEMANA {t}:")
                connected_nodes_t = torch.unique(edge_index_t)
                num_connected_t = connected_nodes_t.size(0)
                num_isolated_t = self.graph.num_nodes - num_connected_t

                var, std = self.calculate_neighbor_variance(week=t)
                if var > max_var:
                    max_var = var
                if var < min_var:
                    min_var = var
                print(f"\t\t-> Varianza Media de Vecinos: {(var*100.0):.4f}, Desviaci√≥n T√≠pica: {(std*10.0):.4f} puntos")
                acc_var += var
                acc_std += std

                if num_isolated_t > 0:
                    print(f"\t\t‚ö†Ô∏è Hay {num_isolated_t} ({num_isolated_t/self.graph.num_nodes*100:.2f}%) nodos aislados.")
                else:
                    print(f"\t\t‚úÖ No hay nodos aislados.")
            
            metrics['dynamic_max_variance'] = max_var
            metrics['dynamic_min_variance'] = min_var
            metrics['dynamic_avg_variance'] = acc_var / len(self.graph.dynamic_edge_indices)
            print(f"\tPROMEDIO SEMANAL -> Varianza: {(acc_var/len(self.graph.dynamic_edge_indices)*100.0):.4f}, Desviaci√≥n T√≠pica: {(acc_std/len(self.graph.dynamic_edge_indices)*10.0):.4f} puntos")
        
        print("TEST DE HOMOFILIA GLOBAL:")
        # Calcular homofilia global
        homophily = self.calculate_grade_homophily()
        metrics['grade_homophily'] = homophily
        print(f"\tüìä Correlaci√≥n (Homofilia) Notas-Vecinos: {homophily:.4f}")

        # Calcular asortatividad
        assort = self.calc_assortativity()
        metrics['assortativity'] = assort
        print(f"\tüîó Asortatividad: {assort:.4f}")

        # Calcular energ√≠a de Dirichlet
        dirichlet_energy = self.calc_dirichlet_energy()
        metrics['dirichlet_energy'] = dirichlet_energy
        print(f"\t‚ö° Energ√≠a de Dirichlet Media: {dirichlet_energy:.4f} (M√°s bajo = Mejor suavidad entre vecinos)")

        return metrics
        
    def test_all_graphs(self):
        """Funci√≥n para testear todos los grafos en la carpeta GRAPH_DIR."""
        graphs = [f for f in os.listdir(GRAPH_DIR) if f.endswith('.pt')]
        all_metrics = {}
        
        for g in graphs:
            print(f"\n================= TESTEANDO GRAFO: {g} =================")
            self.graph_path = os.path.join(GRAPH_DIR, g)
            self.graph: Data = self.load_graph()
            metrics = self.test_graph(graph_path=self.graph_path)
            all_metrics[g] = metrics
        
        return all_metrics
        
    def calculate_neighbor_variance(self, week: int = None):
        """
        Calcula la varianza media de las notas de los vecinos para evaluar la calidad del grafo.
    
        Returns:
            avg_variance: La varianza media de todo el grafo.
        """
        
        # Aseguramos que y sea plano [N]
        y_flat = self.graph.y.squeeze()
        
        # Obtenemos origen (src) y destino (dst) de las aristas
        # src son los nodos para los que vamos a calcular la varianza de sus vecinos (dst)
        if not week:
            src, dst = self.graph.edge_index
        elif hasattr(self.graph, 'dynamic_edge_indices') and week < len(self.graph.dynamic_edge_indices):
            src, dst = self.graph.dynamic_edge_indices[week]
        else:
            raise ValueError("Semana inv√°lida para grafo din√°mico.")

        # Preparamos un tensor para guardar la varianza de cada alumno
        num_nodes = y_flat.shape[0]
        variances = []
        
        # --- BUCLE DE C√ÅLCULO ---
        # Nota: Como N es peque√±o (alumnos < 500), un bucle es r√°pido y legible.
        # Si tuvieras millones de nodos, usar√≠amos scatter_reduce.
        
        count_valid_nodes = 0
        
        for i in range(num_nodes):
            # 1. Buscar qui√©nes son los vecinos del alumno 'i'
            # edge_index[0] == i busca todas las aristas que salen de i
            neighbor_indices = dst[src == i]
            
            # Si no tiene vecinos (o solo 1), la varianza no es fiable/calculable
            if len(neighbor_indices) < 2:
                continue
                
            # 2. Obtener las notas de esos vecinos
            neighbor_grades = y_flat[neighbor_indices]
            
            # 3. Calcular varianza de esas notas
            # unbiased=False para varianza poblacional (divide por N), True para muestral (N-1)
            var = torch.var(neighbor_grades, unbiased=True) 
            variances.append(var)
            count_valid_nodes += 1

        if len(variances) == 0:
            print(f"‚ö†Ô∏è No se pudo calcular varianza (¬øsin vecinos?).")
            return float('inf')

        # 4. Promediar las varianzas de todos los alumnos
        variances_tensor = torch.stack(variances)
        avg_variance = torch.mean(variances_tensor).item()
        std_dev_neighbors = torch.sqrt(torch.tensor(avg_variance)).item() # Desviaci√≥n t√≠pica promedio    
        
        return avg_variance, std_dev_neighbors
    
    def get_graph_outliers(self, threshold=0.3):
        """Devuelve IDs de alumnos cuya nota difiere mucho de la media de sus vecinos."""
        y_flat = self.graph.y.squeeze()
        src, dst = self.graph.edge_index
        outliers = []
        
        for i in range(y_flat.shape[0]):
            neighbors = dst[src == i]
            if len(neighbors) < 1: continue
            
            mean_neighbor_grade = torch.mean(y_flat[neighbors])
            my_grade = y_flat[i]
            
            diff = torch.abs(my_grade - mean_neighbor_grade)
            
            if diff > threshold:
                outliers.append(i)
                
        return outliers

    def calculate_grade_homophily(self):
        """Calcula la correlaci√≥n entre nota del estudiante y nota media de sus vecinos."""
        src, dst = self.graph.edge_index
        y = self.graph.y.squeeze()
        
        # Calcular media de vecinos
        # scatter_mean requiere torch_scatter, si no tienes, usamos bucle o pandas
        # Versi√≥n simple con pandas para no complicar dependencias:
        
        df = pd.DataFrame({'src': src.cpu(), 'dst': dst.cpu(), 'grade_dst': y[dst].cpu()})
        
        # Agrupamos por nodo origen y calculamos la media de sus destinos
        neighbor_means = df.groupby('src')['grade_dst'].mean()
        
        # Alineamos con las notas reales
        # Ojo: puede haber nodos sin vecinos que no salgan en el groupby
        df_corr = pd.DataFrame({'my_grade': y.cpu().numpy()})
        df_corr['neighbor_mean'] = neighbor_means
        
        # Limpiamos NaNs (nodos aislados)
        df_corr = df_corr.dropna()
        
        correlation = df_corr['my_grade'].corr(df_corr['neighbor_mean'])
        return correlation

    def calc_assortativity(self):
        # Convertimos a NetworkX para usar sus m√©tricas probadas
        G = to_networkx(self.graph, to_undirected=True)
        
        # Asignamos la nota como atributo al nodo
        y_np = self.graph.y.squeeze().cpu().numpy()
        attrs = {i: {'grade': val} for i, val in enumerate(y_np)}
        nx.set_node_attributes(G, attrs)
        
        # Calculamos asortatividad
        assortativity = nx.numeric_assortativity_coefficient(G, 'grade')
        return assortativity

    def calc_dirichlet_energy(self):
        src, dst = self.graph.edge_index
        y = self.graph.y.squeeze()
        
        # Diferencia al cuadrado entre vecinos
        squared_diff = (y[src] - y[dst]) ** 2
        energy = torch.sum(squared_diff).item()
        
        # Normalizar por n√∫mero de aristas para que sea interpretable
        mean_energy = energy / self.graph.edge_index.shape[1]
        
        return mean_energy
    
    def _select_graph(self):
        """Funci√≥n para listar los grafos guardados en la carpeta correspondiente y permitir al usuario seleccionar uno."""
        graphs = [f for f in os.listdir(GRAPH_DIR) if f.endswith('.pt')]
        if not graphs:
            print("No hay grafos guardados en la carpeta.")
            return None
        
        print("Grafos disponibles:")
        for i, g in enumerate(graphs):
            print(f"{i+1}. {g}")
        
        choice = int(input("Selecciona el n√∫mero del grafo que quieres cargar: ")) - 1
        if 0 <= choice < len(graphs):
            return os.path.join(GRAPH_DIR, graphs[choice])
        else:
            print("Selecci√≥n inv√°lida.")
            return None

    def save_metrics(self, metrics: dict, output_path: str):
        """Guarda las m√©tricas en un archivo CSV."""
        df = pd.DataFrame.from_dict(metrics, orient='index')
        df.to_csv(output_path)
        print(f"M√©tricas guardadas en {output_path}")
    
    ###################### VISUALIZACI√ìN DE M√âTRICAS ######################
    # Funci√≥n para extraer qu√© tipo de grafo es (Asistencia, Notas, H√≠brido...)
    def parse_info(self,filename):
        # Formato esperado: Metodo_Datos_graph_KNN.pt
        # Ej: Temp_a_graph_5NN.pt
        clean = filename.replace('.pt', '')
        parts = clean.split('_')
        
        # --- A. ESTRATEGIA DE PROCESAMIENTO ---
        method_code = parts[0]
        method_map = {
            'Temp': 'Temporal\n(Secuencia completa)',
            'MP': 'Mean Pooling\n(Media semanal)',
            'Concat': 'Concatenation\n(Aplanado)',
            'LDS': 'LDS (Learnable)'
        }
        method_label = method_map.get(method_code, method_code)
        
        # --- B. FUENTE DE DATOS ---
        data_code = parts[1]
        data_map = {
            'a': 'Solo Asistencia',
            'g': 'Solo Notas',
            'ag': 'H√≠brido (A+N)',
            'ga': 'H√≠brido (A+N)',
            'f3w': 'Primeras 3 Semanas'
        }
        data_label = data_map.get(data_code, data_code)
        
        return pd.Series([method_label, data_label])
    
    # ==========================================
    # GR√ÅFICO DE HOMOFILIA (AGRUPAMIENTO)
    # ==========================================
    def plot_homophily(self, df, save_path= METRICS_MEDIA_DIR + 'grafico_homofilia.png'):
        """Genera el gr√°fico de Homofilia (Correlaci√≥n Notas-Vecinos)."""
        plt.figure(figsize=(10, 6))
        sns.set_style("whitegrid")
        
        sns.barplot(
            data=df,
            x='Datos',
            y='grade_homophily',
            hue='Estrategia',
            palette='viridis',
            edgecolor='black'
        )
        
        plt.title('Calidad de Agrupamiento (Homofilia)\n¬øLos alumnos se conectan con compa√±eros de notas similares?', 
                fontsize=14, fontweight='bold')
        plt.ylabel('Correlaci√≥n de Pearson (Mayor es mejor)', fontsize=12)
        plt.xlabel('Fuente de Datos', fontsize=12)
        plt.ylim(0, 1.05)
        plt.legend(title='Estrategia', loc='upper right')
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300)
        print(f"‚úÖ Gr√°fico guardado: {save_path}")
        plt.close() # Cierra la figura para liberar memoria

    # ==========================================
    # GR√ÅFICO DE SUAVIDAD (VARIANZA)
    # ==========================================
    def plot_smoothness(self, df, save_path= METRICS_MEDIA_DIR +'grafico_suavidad.png'):
        """Genera el gr√°fico de Dispersi√≥n de vecinos (Desviaci√≥n T√≠pica)."""
        plt.figure(figsize=(10, 6))
        sns.set_style("whitegrid")
        
        sns.barplot(
            data=df,
            x='Datos',
            y='neighbor_std_dev', # Usamos Std Dev porque es m√°s interpretable que Varianza
            hue='Estrategia',
            palette='magma',
            edgecolor='black'
        )
        
        plt.title('Estabilidad de la Se√±al en el Grafo\n¬øCu√°nta diferencia de nota hay entre un alumno y sus vecinos?', 
                fontsize=14, fontweight='bold')
        plt.ylabel('Desviaci√≥n T√≠pica (Menor es mejor)', fontsize=12)
        plt.xlabel('Fuente de Datos', fontsize=12)
        plt.legend(title='Estrategia', loc='upper right')
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300)
        print(f"‚úÖ Gr√°fico guardado: {save_path}")
        plt.close()

    # ==========================================
    # GR√ÅFICO DE RUIDO (OUTLIERS)
    # ==========================================
    def plot_outliers(self, df, save_path= METRICS_MEDIA_DIR +'grafico_outliers.png'):
        """Genera el gr√°fico de Nodos At√≠picos (Outliers)."""
        plt.figure(figsize=(10, 6))
        sns.set_style("whitegrid")
        
        sns.barplot(
            data=df,
            x='Datos',
            y='num_outliers',
            hue='Estrategia',
            palette='Reds',
            edgecolor='black'
        )
        
        plt.title('Nodos At√≠picos (Ruido)\nCantidad de alumnos mal conectados', 
                fontsize=14, fontweight='bold')
        plt.ylabel('N√∫mero de Alumnos (Menor es mejor)', fontsize=12)
        plt.xlabel('Fuente de Datos', fontsize=12)
        plt.legend(title='Estrategia', loc='upper right')
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300)
        print(f"‚úÖ Gr√°fico guardado: {save_path}")
        plt.close()
    
    # ==========================================
    # GR√ÅFICO DE ASORTATIVIDAD
    # ==========================================
    def plot_assortativity(self, df, save_path= METRICS_MEDIA_DIR +'grafico_asortatividad.png'):
        """
        Genera el gr√°fico de Asortatividad Num√©rica.
        Mide si los nodos con valores altos se conectan con otros altos.
        """
        plt.figure(figsize=(10, 6))
        sns.set_style("whitegrid")
        
        sns.barplot(
            data=df,
            x='Datos',
            y='assortativity',
            hue='Estrategia',
            palette='plasma', # Usamos una paleta distinta para diferenciar
            edgecolor='black'
        )
        
        plt.title('Asortatividad del Grafo\n¬øSe conectan los estudiantes con perfiles id√©nticos?', 
                fontsize=14, fontweight='bold')
        plt.ylabel('Coeficiente de Asortatividad (Cercano a 1 es mejor)', fontsize=12)
        plt.xlabel('Fuente de Datos', fontsize=12)
        plt.ylim(0, 1.05) # Rango te√≥rico -1 a 1, pero esperamos positivo
        plt.legend(title='Estrategia', loc='upper right')
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300)
        print(f"‚úÖ Gr√°fico guardado: {save_path}")
        plt.close()

    # ==========================================
    # GR√ÅFICO DE ENERG√çA DE DIRICHLET
    # ==========================================
    def plot_dirichlet(self,df, save_path=METRICS_MEDIA_DIR+'grafico_energia.png'):
        """
        Genera el gr√°fico de Energ√≠a de Dirichlet.
        Mide la 'suavidad' global. Cuanto m√°s bajo, m√°s suave es la transici√≥n de notas.
        """
        plt.figure(figsize=(10, 6))
        sns.set_style("whitegrid")
        
        sns.barplot(
            data=df,
            x='Datos',
            y='dirichlet_energy',
            hue='Estrategia',
            palette='coolwarm',
            edgecolor='black'
        )
        
        plt.title('Energ√≠a de Dirichlet (Suavidad Global)\n¬øCu√°n bruscos son los cambios de nota en el grafo?', 
                fontsize=14, fontweight='bold')
        plt.ylabel('Energ√≠a Media (Menor es mejor)', fontsize=12)
        plt.xlabel('Fuente de Datos', fontsize=12)
        plt.legend(title='Estrategia', loc='upper right')
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300)
        print(f"‚úÖ Gr√°fico guardado: {save_path}")
        plt.close()

    def visualize_metrics(self, metrics_path: str):
        """Genera gr√°ficos a partir del archivo de m√©tricas guardado."""
        
        # 1. CARGAR DATOS
        df_metrics = pd.read_csv(metrics_path)

        # Renombrar la primera columna si no tiene nombre
        if 'Unnamed: 0' in df_metrics.columns:
            df_metrics = df_metrics.rename(columns={'Unnamed: 0': 'Filename'})
        elif df_metrics.columns[0] != 'Filename':
            df_metrics.columns.values[0] = 'Filename'

        
        df_metrics[['Estrategia', 'Datos']] = df_metrics['Filename'].apply(self.parse_info)

        
        print("Datos procesados:")
        print(df_metrics[['Estrategia', 'Datos', 'grade_homophily']].head())
        
        
        self.plot_homophily(df_metrics)
        self.plot_smoothness(df_metrics)
        self.plot_outliers(df_metrics)
        self.plot_assortativity(df_metrics)
        self.plot_dirichlet(df_metrics)
        
        print("\nüéâ ¬°Proceso completado! Tienes 5 nuevas im√°genes.")
        

if __name__== "__main__":
    
    tester = GraphTester()
    metrics = tester.test_all_graphs()
    path_metrics = "data/metrics/graph_metrics.csv"
    tester.save_metrics(metrics, path_metrics)
    tester.visualize_metrics(path_metrics)