# üéì Predicci√≥n de Rendimiento Acad√©mico mediante Redes Neuronales de Grafos (GNN)

Este repositorio contiene el c√≥digo fuente desarrollado para el Trabajo de Fin de Grado (TFG) centrado en la predicci√≥n temprana del rendimiento estudiantil. El sistema utiliza t√©cnicas avanzadas de **Deep Learning en Grafos (Graph Deep Learning)** para modelar no solo el historial individual del alumno, sino tambi√©n la influencia de su entorno social y acad√©mico.

## üöÄ Caracter√≠sticas Principales

El proyecto implementa un pipeline completo de *Machine Learning* educativo, desde el procesamiento de datos crudos hasta la visualizaci√≥n de predicciones.

### 1. Ingenier√≠a de Datos y Grafos (`dataLoader.py`, `graphCreator.py`)
* **Procesamiento Multimodal:** Integra datos de asistencia, calificaciones (seguimiento continuo) y encuestas.
* **Estandarizaci√≥n Robusta:** Normalizaci√≥n para garantizar la convergencia de redes neuronales.
* **Construcci√≥n Din√°mica de Grafos:** Generaci√≥n de grafos de estudiantes ($k$-NN) basados en diferentes perfiles de similitud:
    * `a`: Solo Asistencia.
    * `g`: Solo Notas.
    * `a&g`: H√≠brido (Asistencia + Notas).
    * `f3w`: Alerta Temprana (Primeras 3 semanas).
* **Dualidad Est√°tica/Temporal:** Soporte para grafos est√°ticos (snapshot √∫nico) y grafos din√°micos (evoluci√≥n semana a semana).
* **NOTA IMPORTANTE:** No se utilizan las notas de los parciales te√≥ricos de la asignatura ya que con estos son con los que se calcula la nota final. Solo se usan las notas de seguimiento continuo.

### 2. Arquitectura de Modelos (`model.py`)
Implementaci√≥n modular de modelos de Estado del Arte (SOTA) comparables bajo el mismo framework:
* **Baselines:**
    * `LSTM`: Red recurrente pura (ignora la estructura social).
* **GNNs Est√°ticas (Spatial):**
    * `GCN` (Graph Convolutional Network).
    * `GAT` (Graph Attention Network) con Multi-Head Attention.
    * `GraphSAGE` (Inductive Representation Learning).
* **GNN Espacio-Temporal (Spatio-Temporal):**
    * `STGNN`: Arquitectura h√≠brida personalizada que combina convoluciones gr√°ficas frame a frame con una LSTM para capturar la evoluci√≥n temporal de los embeddings sociales.

### 3. Entrenamiento Robusto y Validaci√≥n (, `modelTrainer.py`, `modelTester.py`)
* **Validaci√≥n Cruzada (K-Fold Cross-Validation):** Evaluaci√≥n rigurosa (k=5) para garantizar la robustez de los resultados.
* **Estrategias Anti-Overfitting:**
    * *Early Stopping*.
    * **Shake & Restart:** Mecanismo avanzado que inyecta ruido a los pesos y reinicia el optimizador si el modelo cae en m√≠nimos locales (colapso a la media).
* **M√©tricas Completas:** Evaluaci√≥n simult√°nea de Regresi√≥n ($R^2$, MAE, RMSE) y Clasificaci√≥n (Accuracy, F1-Score para detecci√≥n de riesgo).
* **Entrenamiento de Modelos Flexibles:** Puede entrenar modelos para que sean √∫tiles en entradas de datos temporales incompletas (menos semanas).

### 4. Visualizaci√≥n y An√°lisis (`graphTester.py`, `predictionsVisualizer.py`)
* **An√°lisis de Homofilia:** M√©tricas para cuantificar si "los iguales se juntan con iguales" (Assortativity, Dirichlet Energy).
* **Visualizaci√≥n de Grafos:** Generaci√≥n de GIFs para observar la evoluci√≥n de las conexiones entre alumnos.
* **Gr√°ficas de Rendimiento:** Scatter plots (Predicci√≥n vs Realidad) y Line plots ordenados para diagnosticar el comportamiento del modelo.

### 5. Estudio de Influencia de Features y Weeks (Explainability) (`modelExplainability.py`)
* **Ablation Studies:** Evaluaci√≥n del impacto de las diferentes features estudiadas y semanas registradas
---

## ‚öôÔ∏è Configuraciones Probadas

El sistema permite la combinaci√≥n flexible de diferentes estrategias de entrada y modelado:

| Estrategia de Datos (`cat_opt`) | Descripci√≥n | Modelos Compatibles |
| :--- | :--- | :--- |
| **MP (Mean Pooling)** | Promedio de todas las semanas. Visi√≥n est√°tica del curso. | GCN, GAT, SAGE |
| **Concat** | Concatenaci√≥n de todas las semanas en un vector largo. | MLP (impl√≠cito en GNNs) |
| **Temp (Temporal)** | Secuencia temporal `[N, Weeks, Features]`. | LSTM, STGNN |

**Perfiles de Similitud para el Grafo:**
* **`a&g` (Asistencia + Notas):** El grafo conecta alumnos con h√°bitos de asistencia y rendimiento similares. (Configuraci√≥n por defecto recomendada).

---

## üìä Resultados Experimentales

A continuaci√≥n se presentan los resultados obtenidos tras la validaci√≥n cruzada (5-Folds) en el conjunto de datos final.

*(Copia y pega aqu√≠ la tabla que imprime tu script `main.py` al finalizar)*

| Modelo | MAE (Error) ‚Üì | R¬≤ (Explicabilidad) ‚Üë | Accuracy (Clasif.) ‚Üë | F1-Score (Riesgo) ‚Üë |
| :--- | :---: | :---: | :---: | :---: |
**LSTM** | 0.680404 +- 0.081843 | 0.627564 | 0.930476 | 0.929526
**GCN** | 0.953232 +- 0.260395 | 0.276488 | 0.796190 | 0.783408
**GAT** | 0.936292 +- 0.165051 | 0.298808 | 0.822857 | 0.797644
**SAGE** | 0.691374 +- 0.091066 | 0.607332 | 0.890476 | 0.866539
**STGNN** | 0.751133 +- 0.064971 | 0.506790 | 0.877143 | 0.851230

> **Interpretaci√≥n:**
> * **MAE:** Error medio absoluto en puntos (sobre 10).
> * **R¬≤:** Proporci√≥n de la varianza de las notas explicada por el modelo.
> * **F1-Score:** M√©trica cr√≠tica para evaluar la capacidad de detectar alumnos suspensos sin falsas alarmas.

## ‚öôÔ∏è Configuraci√≥n del Entrenamiento y Hiperpar√°metros Ganadores (Por ahora)

A continuaci√≥n se detallan los hiperpar√°metros y configuraciones utilizadas para obtener los resultados experimentales. Estos valores se encuentran definidos en `src/model.py` y `src/main.py`.

### üéõÔ∏è Hiperpar√°metros Generales
Configuraci√≥n por defecto del `EntrenadorGNN`:

| Par√°metro | Valor | Descripci√≥n |
| :--- | :---: | :--- |
| **√âpocas (Epochs)** | `500` | M√°ximo n√∫mero de iteraciones de entrenamiento. |
| **Learning Rate (LR)** | `0.01` | Tasa de aprendizaje inicial. |
| **Hidden Dimension** | `32` | Tama√±o de los vectores de caracter√≠sticas en capas ocultas. |
| **Num Layers** | `2` | N√∫mero de capas de convoluci√≥n (GNN) o recurrencia. |
| **Dropout** | `0.2` | Probabilidad de desactivaci√≥n de neuronas (Regularizaci√≥n). |
| **Weight Decay** | `5e-4` | Penalizaci√≥n L2 en el optimizador Adam. |
| **Paciencia (Early Stop)**| `50` | √âpocas sin mejora antes de activar *Shake* o detener. |
| **Max Restarts** | `3` | N√∫mero m√°ximo de reinicios permitidos. |

### üß† Estrategias de Optimizaci√≥n
El sistema implementa mecanismos avanzados para evitar el colapso a la media y los m√≠nimos locales:

* **Optimizador:** `Adam`.
* **Funci√≥n de P√©rdida:** `MSELoss` (Error Cuadr√°tico Medio) sobre salidas normalizadas [0, 1].
* **Scheduler (LR):** `ReduceLROnPlateau` (DESACTIVADO actualmente).
    * Modo: `max` (Maximizar $R^2$).
    * Factor: `0.5` (Reduce LR a la mitad).
    * Paciencia: `10` √©pocas.
* **Mecanismo "Shake & Restart":**
    * **Vidas Extra:** `3` reinicios permitidos.
    * **Inyecci√≥n de Ruido:** Ruido gaussiano inicial ($\sigma=0.08$) con decaimiento exponencial ($0.8^n$) en cada reinicio.
    * **Reinicio de LR:** Se reduce el LR actual al 50% tras cada *Shake*.

### üèóÔ∏è Arquitectura de Modelos Espec√≠ficos
Detalles de configuraci√≥n interna para cada variante:

* **GAT (Graph Attention Network):**
    * **Heads:** `2` cabezales de atenci√≥n.
    * Activaci√≥n: `ELU`.
* **GraphSAGE:**
    * **Agregador:** `LSTM` (requiere ordenaci√≥n de vecinos).
    * Activaci√≥n: `ReLU`.
* **STGNN (Espacio-Temporal):**
    * **Backbone Espacial:** GAT (2 heads).
    * **Backbone Temporal:** LSTM (batch_first=True).
    * **Pipeline:** $GNN_{t} \rightarrow Stack \rightarrow LSTM \rightarrow Linear$.

### üß¨ Configuraci√≥n del Grafo y Datos
Definida en `graphCreator.py` y `main.py`:

* **Construcci√≥n del Grafo:** $k$-NN (k-Nearest Neighbors).
    * **Vecinos ($k$):** `5`.
    * **Perfil de Similitud:** `'a&g'` (Basado en vectores de Asistencia + Notas).
    * **M√©trica:** Distancia Euclidiana.
* **Preprocesamiento:**
    * **Target ($Y$):** Normalizado en rango $[0, 1]$ (Nota / 10).
    * **Validaci√≥n Cruzada:** 5-Fold Cross Validation (`shuffle=True`, `random_state=42`).
---

## üõ†Ô∏è Instalaci√≥n y Uso

1.  **Requisitos:**
    ```bash
    pip install torch torch-geometric pandas numpy scikit-learn matplotlib seaborn imageio
    ```
2.  **Estructura de Datos:**
    Aseg√∫rate de tener los archivos CSV (`asistencia.csv`, `seguimiento.csv`, etc.) en la carpeta `./data/`.

3.  **Ejecuci√≥n:**
    Para entrenar los modelos, evaluar y generar gr√°ficas:
    ```bash
    python src/main.py
    ```

## ToDo list
* [ ] Probar otros perfiles de similitud para el grafo

---
*Trabajo de Fin de Grado - Ingenier√≠a Inform√°tica y Matem√°ticas*


